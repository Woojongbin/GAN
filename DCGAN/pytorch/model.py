# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uhHSYrZTA6mAd4fFWxiENdZZ6JCI3Tf1
"""

import torch.nn as nn
import torch.nn.functional as F

def gen_block(in_f, out_f, *args, **kwargs):
  return nn.Sequential(
      nn.ConvTranspose2d(in_f,out_f,*args,**kwargs),
      nn.BatchNorm2d(out_f),
      nn.ReLU(True)
  )

class Generator(nn.Module):
  def __init__(self, z_dim, hidden_dim, out_channel):
    super(Generator, self).__init__()
    self.z_dim = z_dim
    self.hidden_dim = hidden_dim 
    self.out_channel = out_channel

    self.decoder = nn.Sequential(
        gen_block(self.z_dim, self.hidden_dim*8, 4, 1, 0,bias=False),
        gen_block(self.hidden_dim*8, self.hidden_dim*4, 4, 2, 1, bias=False),
        gen_block(self.hidden_dim*4, self.hidden_dim*2, 4, 2, 1, bias=False),
        gen_block(self.hidden_dim*2, self.hidden_dim, 4, 2, 1, bias=False),
        nn.ConvTranspose2d(self.hidden_dim, self.out_channel, 4, 2, 1, bias=False),
        nn.Tanh()
    )

  def forward(self, x):
    return self.decoder(x)

def dis_block(in_f, out_f, *args, **kwargs):
  return nn.Sequential(
      nn.Conv2d(in_f,out_f,*args,**kwargs),
      nn.BatchNorm2d(out_f),
      nn.LeakyReLU(0.2, inplace=True)
  )

class Discriminator(nn.Module):
  def __init__(self, input_channel, hidden_dim):
    super(Discriminator, self).__init__()
    self.input_channel = input_channel
    self.hidden_dim = hidden_dim

    self.encoder = nn.Sequential(
        dis_block(self.input_channel, self.hidden_dim, 4, 2, 1,bias=False),
        dis_block(self.hidden_dim, self.hidden_dim*2, 4, 2, 1, bias=False),
        dis_block(self.hidden_dim*2, self.hidden_dim*4, 4, 2, 1, bias=False),
        dis_block(self.hidden_dim*4, self.hidden_dim*8, 4, 2, 1, bias=False),
        nn.Conv2d(self.hidden_dim*8, 1, 4, 1, 0, bias=False),
        nn.Sigmoid()
    )

  def forward(self, x):
    return self.encoder(x).view(-1,1).squeeze(1)


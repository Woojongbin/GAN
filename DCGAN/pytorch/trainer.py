# -*- coding: utf-8 -*-
"""trainer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MjSsJi1aO7LaeFjDwPTerrz4_ooxPEQg
"""

import itertools
import os
import time

from datetime import datetime

import numpy as np
import torch
import torchvision.utils as vutils

import utils

from model import Discriminator
from model import Generator

def _weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)
        torch.nn.init.constant_(m.bias.data, 0.0)

class Trainer(object):
  def __init__(self,device,data_loader,in_c,h_c,z_dim,lr):
    
    self.device = device
    self.data_loader = data_loader
    self.in_c = in_c
    self.h_c = h_c
    self.z_dim = z_dim
    self.lr = lr

    self.netD = Discriminator(self.in_c, self.h_c)
    self.netD.apply(_weights_init)
    self.netD.to(self.device)

    self.netG = Generator(self.z_dim, self.h_c, self.in_c)
    self.netG.apply(_weights_init)
    self.netG.to(self.device)

    self.optim_D = None
    self.optim_G = None

    self.criterion = torch.nn.BCELoss()

    self.optimizerD = torch.optim.Adam(self.netD.parameters(), lr=self.lr, betas=(0.5, 0.999))
    self.optimizerG = torch.optim.Adam(self.netG.parameters(), lr=self.lr, betas=(0.5, 0.999))
  
  def train(self, epochs, log_interval=100, out_dir='', verbose=True):
    self.netG.train()
    self.netD.train()
    viz_noise = torch.randn(len(self.data_loader), self.z_dim, 1, 1, device=self.device)
    for epoch in range(epochs):
      for i, data in enumerate(self.data_loader):
          x_real = data[0].to(self.device)
          real_label = torch.full((x_real.size(0),), 1, device=self.device)
          fake_label = torch.full((x_real.size(0),), 0, device=self.device)

          # Update D with real data
          self.netD.zero_grad()
          y_real = self.netD(x_real)
          loss_D_real = self.criterion(y_real, real_label)
          loss_D_real.backward()

          # Update D with fake data
          z_noise = torch.randn(x_real.size(0), self.z_dim, 1, 1, device=self.device)
          x_fake = self.netG(z_noise)
          y_fake = self.netD(x_fake.detach())
          loss_D_fake = self.criterion(y_fake, fake_label)
          loss_D_fake.backward()
          self.optimizerD.step()

          # Update G with fake data
          self.netG.zero_grad()
          y_fake_r = self.netD(x_fake)
          loss_G = self.criterion(y_fake_r, real_label)
          loss_G.backward()
          self.optimizerG.step()

          if i % 100 == 0:
              print('Epoch {} [{}/{}] loss_D_real: {:.4f} loss_D_fake: {:.4f} loss_G: {:.4f}'.format(
                  epoch, i, len(self.data_loader),
                  loss_D_real.mean().item(),
                  loss_D_fake.mean().item(),
                  loss_G.mean().item()
              ))
              vutils.save_image(x_real, os.path.join(out_dir, 'real_samples.png'), normalize=True)
              with torch.no_grad():
                  viz_sample = self.netG(viz_noise)
                  vutils.save_image(viz_sample, os.path.join(out_dir, 'fake_samples_{}.png'.format(epoch)), normalize=True)
    save_checkpoint(self.netG.state_dict(), os.path.join(out_dir, 'netG_{}.pth'.format(epoch)))
    save_checkpoint(self.netD.state_dict(), os.path.join(out_dir, 'netD_{}.pth'.format(epoch)))

  def eval():
    pass

